{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "환경: Python2.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic modeling : 문서의 주제를 찾는 모델링 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **LSI(Latent Simantic Indexing)**\n",
    "- **LDA(Latent Dirichlet Allocation)**\n",
    "- TF-IDF\n",
    "- HDP(Hierarchical Dirichlet Process)\n",
    "- Word Representation (Word2Vec)\n",
    "- Document Representation (Doc2Vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why?\n",
    " - 숨겨진 토픽의 패턴을 찾기 위해 토픽 모델을 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependency\n",
    " - Theano\n",
    " - scipy\n",
    " - numpy\n",
    "\n",
    "Python 3.4, 2.7에서 사용 가능\n",
    "\n",
    "Python 3.5의 경우는 Theano가 Python 3.4버젼까지밖에 Dependency가 제공되지 않으므로 안깔림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/gensim_install.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/gensim_install2.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Install Finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Corpus(말뭉치) 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Corpus: 연구를 위한 자료나 정보의 모음\n",
    "\n",
    "NLP(Natural Language Processing)에서 사용하는 Corpus는 문서 전체에 대한 단어들의 집합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가) Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "import pprint\n",
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "              \"A survey of user opinion of computer system response time\",\n",
    "              \"The EPS user interface management system\",\n",
    "              \"System and human system engineering testing of EPS\",\n",
    "              \"Relation of user perceived response time to error measurement\",\n",
    "              \"The generation of random binary unordered trees trees\",\n",
    "              \"The intersection graph of paths in trees\",\n",
    "              \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "              \"Graph minors A survey\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- 전치사 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stoplist = set('for a of the and to in'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "         for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'machine', 'interface', 'lab', 'abc', 'computer', 'applications'],\n",
       " ['survey', 'user', 'opinion', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'management', 'system'],\n",
       " ['system', 'human', 'system', 'engineering', 'testing', 'eps'],\n",
       " ['relation', 'user', 'perceived', 'response', 'time', 'error', 'measurement'],\n",
       " ['generation', 'random', 'binary', 'unordered', 'trees', 'trees'],\n",
       " ['intersection', 'graph', 'paths', 'trees'],\n",
       " ['graph', 'minors', 'iv', 'widths', 'trees', 'well', 'quasi', 'ordering'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어 카운트 숫자가 적은 경우 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "        \n",
    "texts = [[token for token in text if frequency[token] > 1]\n",
    "         for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees', 'trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 나) 사전 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corpora는 말뭉치(corpus) Set을 만들기 위해 사용\n",
    "\n",
    "corpora.Dictionary는 Key, Value값 형태로 Key에는 단어가 들어가며 Value에는 단어의 Frequency에 따라 sorting 후 a-z형태로 나열하여 순서를 나타냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'computer': 1,\n",
      " u'eps': 8,\n",
      " u'graph': 10,\n",
      " u'human': 2,\n",
      " u'interface': 0,\n",
      " u'minors': 11,\n",
      " u'response': 3,\n",
      " u'survey': 5,\n",
      " u'system': 6,\n",
      " u'time': 4,\n",
      " u'trees': 9,\n",
      " u'user': 7}\n"
     ]
    }
   ],
   "source": [
    "dict1 = corpora.Dictionary(texts)\n",
    "dict1.save('./deerwester.dict') \n",
    "pprint.pprint(dict1.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/BOW.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOW(Bag of words)를 통해 문장에서의 단어 분포도를 찾을 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'computer': 1,\n",
      " u'eps': 8,\n",
      " u'graph': 10,\n",
      " u'human': 2,\n",
      " u'interface': 0,\n",
      " u'minors': 11,\n",
      " u'response': 3,\n",
      " u'survey': 5,\n",
      " u'system': 6,\n",
      " u'time': 4,\n",
      " u'trees': 9,\n",
      " u'user': 7}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(dict1.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5, 1), (10, 1), (11, 1)]\n",
      "['graph', 'minors', 'survey']\n"
     ]
    }
   ],
   "source": [
    "# text문장을 추출\n",
    "[dict1.doc2bow(text) for text in texts]\n",
    "\n",
    "# BOW를 통한 단어 파악\n",
    "print(dict1.doc2bow(text))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1)],\n",
      " [(1, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
      " [(0, 1), (6, 1), (7, 1), (8, 1)],\n",
      " [(2, 1), (6, 2), (8, 1)],\n",
      " [(3, 1), (4, 1), (7, 1)],\n",
      " [(9, 2)],\n",
      " [(9, 1), (10, 1)],\n",
      " [(9, 1), (10, 1), (11, 1)],\n",
      " [(5, 1), (10, 1), (11, 1)]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dict1.doc2bow(text) for text in texts]\n",
    "pprint.pprint(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Corpus in Matrix Maret Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 일반적인 Market Matrix형태\n",
    "corpora.MmCorpus.serialize('./deerwester.mm',corpus)\n",
    "\n",
    "# SVM형태의 corpus를 나타낼 때 사용하는 형태\n",
    "corpora.SvmLightCorpus.serialize('./deerwester.svmlight',corpus)\n",
    "\n",
    "# EM 알고리즘(expectation-maximization algorithm, 기대값 최대화)을 나타낼 때 사용 : \n",
    "corpora.BleiCorpus.serialize('./deerwester.lda-c',corpus)\n",
    "\n",
    "# Gibbs 샘플링을 통한 LDA분석에 사용\n",
    "corpora.LowCorpus.serialize('./deerwester.low',corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적인 Corpus사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpora.MmCorpus.serialize('./deerwester.mm',corpus)\n",
    "mm=corpora.MmCorpus('./deerwester.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MmCorpus(9 documents, 12 features, 28 non-zero entries)\n"
     ]
    }
   ],
   "source": [
    "print(mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyCorpus(object):\n",
    "    def __iter__(self):\n",
    "        for line in open('mycorpus.txt'):\n",
    "            yield dictionary.doc2bow(line.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_memory_friendly = MyCorpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'a': 8,\n",
      " u'abc': 0,\n",
      " u'and': 19,\n",
      " u'applications': 4,\n",
      " u'binary': 28,\n",
      " u'computer': 5,\n",
      " u'engineering': 20,\n",
      " u'eps': 18,\n",
      " u'error': 26,\n",
      " u'for': 1,\n",
      " u'generation': 27,\n",
      " u'graph': 35,\n",
      " u'human': 6,\n",
      " u'in': 34,\n",
      " u'interface': 7,\n",
      " u'intersection': 33,\n",
      " u'iv': 40,\n",
      " u'lab': 2,\n",
      " u'machine': 3,\n",
      " u'management': 17,\n",
      " u'measurement': 24,\n",
      " u'minors': 36,\n",
      " u'of': 9,\n",
      " u'opinion': 14,\n",
      " u'ordering': 37,\n",
      " u'paths': 32,\n",
      " u'perceived': 23,\n",
      " u'quasi': 41,\n",
      " u'random': 29,\n",
      " u'relation': 25,\n",
      " u'response': 15,\n",
      " u'survey': 11,\n",
      " u'system': 10,\n",
      " u'testing': 21,\n",
      " u'the': 16,\n",
      " u'time': 13,\n",
      " u'to': 22,\n",
      " u'trees': 31,\n",
      " u'unordered': 30,\n",
      " u'user': 12,\n",
      " u'well': 39,\n",
      " u'widths': 38}\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(line.lower().split() for line in open('data/mycorpus.txt'))\n",
    "pprint.pprint(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LSI(Latent Simantic Indexing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSI는 문서에 포함되어 있는 키워드를 기록할 뿐만 아니라, 문서 컬렉션 전체를 평가하여 어떤 문서가 비슷한 단어를 포함하고 있는 지를 찾아낸다. LSI는 많은 단어를 공유하는 문서들이 결과적으로 의미면에서 (semantically) 가까운 것으로 간주하며, 공유하는 단어가 적으면 의미적으로 먼 것으로 여김 \n",
    "\n",
    "LSI 알고리즘은 단어의 뜻을 이해하지는 못하지만, 단어들이 보여주는 패턴을 인식 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LSI는 문서에 포함되어 있는 키워드를 기록할 뿐만 아니라, 문서 컬렉션 전체를 평가하여 어떤 문서가 비슷한 단어를 포함하고 있는지를 찾아냄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T1)The Neatest Little **Guide** to **Stock Market Investing**\n",
    "\n",
    "T2) **Investing** For **Dummies**, 4th Edition\n",
    "\n",
    "T3) The Little **Book** of Common Sense **Investing**: The Only Way to Guarantee Your Fair Share of **Stock Market** Returns\n",
    "\n",
    "T4) The Little **Book** of **Value Investing**\n",
    "\n",
    "T5) **Value Investing**: From Graham to Buffett and Beyond\n",
    "\n",
    "T6) **Rich Dad’s Guide** to **Investing**: What the **Rich** Invest in, That the Poor and the Middle Class Do Not!\n",
    "\n",
    "T7) **Investing** in **Real Estate**, 5th Edition\n",
    "\n",
    "T8) **Stock Investing** For **Dummies**\n",
    "\n",
    "T9) **Rich Dad’s** Advisors: The ABC’s of **Real Estate Investing**: The Secrets of Finding Hidden Profits Most Investors Miss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 진행순서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가. 위에서 나타낸 1~9까지의 document 중 단어가 2개 이상인 것만 간추림\n",
    "\n",
    "나. 아래의 그림처럼 Vector를 나타낼 수 있음\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/matrix1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/xygraph2.png\" width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lsi = gensim.models.lsimodel.LsiModel(corpus=mm, id2word=dictionary, num_topics=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.644*\"human\" + 0.403*\"interface\" + 0.301*\"a\" + 0.265*\"machine\" + 0.265*\"applications\" + 0.240*\"for\" + 0.221*\"lab\" + 0.206*\"computer\" + 0.198*\"abc\" + 0.039*\"system\"'),\n",
       " (1,\n",
       "  u'-0.779*\"of\" + -0.501*\"system\" + -0.335*\"survey\" + -0.136*\"computer\" + 0.074*\"human\" + 0.053*\"a\" + 0.040*\"lab\" + 0.031*\"abc\" + -0.012*\"machine\" + -0.012*\"applications\"'),\n",
       " (2,\n",
       "  u'-0.428*\"machine\" + -0.428*\"applications\" + 0.390*\"human\" + 0.354*\"a\" + -0.328*\"interface\" + 0.305*\"lab\" + -0.276*\"computer\" + -0.168*\"for\" + 0.162*\"of\" + 0.151*\"abc\"'),\n",
       " (3,\n",
       "  u'0.567*\"of\" + -0.494*\"survey\" + -0.464*\"system\" + -0.374*\"computer\" + 0.180*\"interface\" + 0.138*\"machine\" + 0.138*\"applications\" + -0.061*\"lab\" + -0.057*\"human\" + 0.035*\"abc\"'),\n",
       " (4,\n",
       "  u'0.593*\"for\" + 0.559*\"abc\" + 0.412*\"lab\" + -0.338*\"human\" + -0.186*\"a\" + -0.087*\"interface\" + -0.068*\"applications\" + -0.068*\"machine\" + -0.015*\"system\" + -0.014*\"survey\"')]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.print_topics(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSI 실제 구하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Example1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Example2.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Example3.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Example4.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Example5.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LDA(Latent Dirichlet Allocation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**사전확률, 사후확률, 기대값, 베이즈 룰 등은 생략**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- 주어진 문서에 대하여 각 문서에 어떤 주제들이 존재하는지에 대한 확률 모형\n",
    "\n",
    "-- 미리 알고 있는 주제별 단어수 분포를 바탕으로, 주어진 문서에서 발견된 단어수 분포를 분석함으로서 해당 문서가 어떤 주제들을 함께 다루고 있을지를 예측할 수 있다\n",
    "\n",
    "- Latent : 잠재적인\n",
    "- Dirichlet : 디리클레  \n",
    "- Allocation : 할당"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 나에게 1만개의 문서가 있다 가정했을 때 1만개의 문서를 구성하고 있는 어떠한 토픽들을 알아내고 싶다고 했을 때 사용할 수 있는 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **\"주말 더 덥다, 일요일엔 장맛비\"** 라는 기사를 보았을 때\n",
    " \n",
    "- 일요일, 기온, 날씨, 주말 이라는 연관된 토픽들을 다룸\n",
    "- 이것처럼 모든 문서는 하나의 토픽에만 속하는 것이 아닌 다른 토픽들의 혼합모델(Mixture model)로 정의할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA는 어떤 문서에 대해 주제 벡터(Theata)가 있고, 앞에서부터 단어를 하나씩 채울 때마다 주제벡터로부터 하나의 주제를 선택하고, 다시 그 주제로부터 단어를 선택하는 방식으로 문서 생성과정을 모델링 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/plate.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ alpha,beta : 코퍼스(말뭉치) 단위로 정해지는 값 $$\n",
    "$$ alpha는 기존문서이며, beta는 토픽을 형성하는 단어의 집합 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\theta : 주제 벡터 $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ w : 단어 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 문서의 **토픽들**을 정하고\n",
    "\n",
    "2. **각 단어**의 **토픽**을 정하며\n",
    "\n",
    "3. 토픽을 형성하는 단어의 집합에서 단어를 **뽑아** 문서에 쓴다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/result.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = gensim.models.ldamodel.LdaModel(corpus=mm, id2word=dictionary, num_topics=10, update_every=1, chunksize=10, passes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  u'0.108*system + 0.108*for + 0.108*applications + 0.108*abc + 0.108*lab + 0.108*survey + 0.010*of + 0.010*computer + 0.010*interface + 0.010*machine'),\n",
       " (8,\n",
       "  u'0.024*of + 0.024*system + 0.024*computer + 0.024*machine + 0.024*survey + 0.024*applications + 0.024*for + 0.024*interface + 0.024*abc + 0.024*lab'),\n",
       " (5,\n",
       "  u'0.108*applications + 0.108*computer + 0.108*interface + 0.108*abc + 0.108*machine + 0.108*human + 0.010*of + 0.010*system + 0.010*lab + 0.010*survey'),\n",
       " (6,\n",
       "  u'0.177*system + 0.177*of + 0.016*computer + 0.016*interface + 0.016*survey + 0.016*lab + 0.016*machine + 0.016*applications + 0.016*for + 0.016*abc')]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
